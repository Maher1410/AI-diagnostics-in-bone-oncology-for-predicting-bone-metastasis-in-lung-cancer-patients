{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Configuration Cell\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import splitfolders\n",
    "from timm.data.auto_augment import rand_augment_transform\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.models import deit_base_patch16_224\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score\n",
    "\n",
    "# Configuration\n",
    "NUM_CLASSES = 6\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LR = 3e-5\n",
    "WARMUP_EPOCHS = 5\n",
    "DATA_ROOT = \"C:\\\\Users\\\\DELL 5540\\\\Desktop\\\\Brain Tumour\\\\Brain Tumour Dataset - Radiology Team - 6 Classes\"\n",
    "SPLIT_ROOT = \"C:\\\\Users\\\\DELL 5540\\\\Desktop\\\\Brain Tumour\\\\Dataset\"\n",
    "NUM_WORKERS = 4\n",
    "SEED = 42\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7622 files [00:09, 785.80 files/s]\n"
     ]
    }
   ],
   "source": [
    "#%% Data Preparation Cell\n",
    "def prepare_dataset():\n",
    "    # Split dataset into train/val/test (70/15/15)\n",
    "    splitfolders.ratio(\n",
    "        DATA_ROOT,\n",
    "        output=SPLIT_ROOT,\n",
    "        seed=SEED,\n",
    "        ratio=(0.7, 0.15, 0.15),\n",
    "        group_prefix=None,\n",
    "        move=False\n",
    "    )\n",
    "\n",
    "prepare_dataset()\n",
    "\n",
    "# DeiT-specific transforms\n",
    "def get_transforms():\n",
    "    # RandAugment parameters from original DeiT paper\n",
    "    ra_params = {\n",
    "        \"translate_const\": 100,\n",
    "        \"img_mean\": tuple([min(255, round(255 * x)) for x in [0.485, 0.456, 0.406]]),\n",
    "    }\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.08, 1.0), ratio=(3/4, 4/3)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        rand_augment_transform(\"rand-m9-mstd0.5\", ra_params),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE + 32),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "train_transform, val_transform = get_transforms()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImageFolder(os.path.join(SPLIT_ROOT, 'train'), train_transform)\n",
    "val_dataset = ImageFolder(os.path.join(SPLIT_ROOT, 'val'), val_transform)\n",
    "test_dataset = ImageFolder(os.path.join(SPLIT_ROOT, 'test'), val_transform)\n",
    "\n",
    "# Get class weights for imbalance handling\n",
    "class_counts = np.bincount(train_dataset.targets)\n",
    "class_weights = torch.tensor(1. / (class_counts / class_counts.max()), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%% Data Visualization Cell\n",
    "def plot_class_distribution():\n",
    "    counts = np.bincount(train_dataset.targets)\n",
    "    class_names = train_dataset.classes\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(class_names, counts)\n",
    "    plt.title('Class Distribution in Training Set')\n",
    "    plt.xlabel('Tumor Type')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Model Definition Cell (Fixed)\n",
    "class BrainTumorDeiT(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.deit = deit_base_patch16_224(pretrained=pretrained)\n",
    "        self.deit.head = nn.Sequential(\n",
    "            nn.Linear(self.deit.head.in_features, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Freeze/unfreeze layers\n",
    "        for param in self.deit.parameters():\n",
    "            param.requires_grad = False\n",
    "        for block in self.deit.blocks[-4:]:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = True\n",
    "        for param in self.deit.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.deit(x)\n",
    "\n",
    "class LitBrainTumor(pl.LightningModule):\n",
    "    def __init__(self, class_weights=None):\n",
    "        super().__init__()\n",
    "        self.model = BrainTumorDeiT()\n",
    "        \n",
    "        # Custom loss function for mixup\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "        # Metrics\n",
    "        self.train_acc = MulticlassAccuracy(num_classes=NUM_CLASSES)\n",
    "        self.val_acc = MulticlassAccuracy(num_classes=NUM_CLASSES)\n",
    "        self.test_acc = MulticlassAccuracy(num_classes=NUM_CLASSES)\n",
    "        self.f1 = MulticlassF1Score(num_classes=NUM_CLASSES)\n",
    "        \n",
    "        # Mixup/Cutmix\n",
    "        self.mixup_fn = Mixup(\n",
    "            mixup_alpha=0.8,\n",
    "            cutmix_alpha=1.0,\n",
    "            prob=1.0,\n",
    "            switch_prob=0.5,\n",
    "            mode='batch',\n",
    "            num_classes=NUM_CLASSES  # Add this line\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x, y = self.mixup_fn(x, y)\n",
    "        logits = self(x)\n",
    "        \n",
    "        # Use standard CrossEntropyLoss for mixup targets\n",
    "        loss = self.criterion(logits, y.argmax(1))  # Changed to use argmax for mixup targets\n",
    "        \n",
    "        self.train_acc(logits.softmax(1), y.argmax(1))\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', self.train_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.CrossEntropyLoss(weight=self.class_weights)(logits, y)\n",
    "        \n",
    "        self.val_acc(logits.softmax(1), y)\n",
    "        self.f1(logits.softmax(1), y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, prog_bar=True)\n",
    "        self.log('val_f1', self.f1, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = nn.CrossEntropyLoss(weight=self.class_weights)(logits, y)\n",
    "        \n",
    "        self.test_acc(logits.softmax(1), y)\n",
    "        self.f1(logits.softmax(1), y)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', self.test_acc)\n",
    "        self.log('test_f1', self.f1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=LR,\n",
    "            weight_decay=0.05,\n",
    "            betas=(0.9, 0.999)\n",
    "        )\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=EPOCHS - WARMUP_EPOCHS,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        warmup = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lambda epoch: min(1., (epoch + 1) / WARMUP_EPOCHS)\n",
    "        )\n",
    "        \n",
    "        return [optimizer], [\n",
    "            {'scheduler': warmup, 'interval': 'epoch', 'frequency': 1},\n",
    "            {'scheduler': scheduler, 'interval': 'epoch', 'frequency': 1}\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 5540\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py:557: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: c:\\Users\\DELL 5540\\Desktop\\Brain Tumour\\lightning_logs\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | BrainTumorDeiT     | 86.2 M\n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | train_acc | MulticlassAccuracy | 0     \n",
      "3 | val_acc   | MulticlassAccuracy | 0     \n",
      "4 | test_acc  | MulticlassAccuracy | 0     \n",
      "5 | f1        | MulticlassF1Score  | 0     \n",
      "-------------------------------------------------\n",
      "28.7 M    Trainable params\n",
      "57.4 M    Non-trainable params\n",
      "86.2 M    Total params\n",
      "344.782   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566b0b7b25e44debacae091c00141117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'LitBrainTumor' object has no attribute 'class_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 61\u001b[0m\n\u001b[0;32m     52\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     53\u001b[0m     test_dataset,\n\u001b[0;32m     54\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Load the best model checkpoint\u001b[39;00m\n\u001b[0;32m     64\u001b[0m best_model \u001b[38;5;241m=\u001b[39m LitBrainTumor\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[0;32m     65\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path,  \u001b[38;5;66;03m# Path to the best checkpoint\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     class_weights\u001b[38;5;241m=\u001b[39mclass_weights  \u001b[38;5;66;03m# Pass class weights to the loaded model\u001b[39;00m\n\u001b[0;32m     67\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    577\u001b[0m     ckpt_path,\n\u001b[0;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m )\n\u001b[1;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 990\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1034\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1036\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1063\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1060\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m-> 1063\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:134\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:391\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    385\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:403\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 68\u001b[0m, in \u001b[0;36mLitBrainTumor.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     66\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     67\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[1;32m---> 68\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weights\u001b[49m)(logits, y)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_acc(logits\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m1\u001b[39m), y)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1(logits\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m1\u001b[39m), y)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LitBrainTumor' object has no attribute 'class_weights'"
     ]
    }
   ],
   "source": [
    "#%% Training Execution Cell (Fixed)\n",
    "# Initialize model with class weights\n",
    "model = LitBrainTumor(class_weights=class_weights)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_f1',  # Monitor F1 score for checkpointing\n",
    "    mode='max',        # Maximize F1 score\n",
    "    save_top_k=3,      # Save top 3 models\n",
    "    filename='best-{epoch}-{val_f1:.2f}'  # Filename format\n",
    ")\n",
    "\n",
    "early_stop = pl.callbacks.EarlyStopping(\n",
    "    monitor='val_f1',  # Monitor F1 score\n",
    "    patience=15,       # Stop after 15 epochs without improvement\n",
    "    mode='max',        # Maximize F1 score\n",
    "    min_delta=0.001    # Minimum improvement required\n",
    ")\n",
    "\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor()  # Monitor learning rate\n",
    "\n",
    "# Trainer configuration\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='auto',  # Automatically select GPU if available\n",
    "    devices=1,           # Use 1 device\n",
    "    max_epochs=EPOCHS,   # Maximum number of epochs\n",
    "    callbacks=[checkpoint, early_stop, lr_monitor],  # Attach callbacks\n",
    "    precision='16-mixed',  # Use mixed precision for faster training\n",
    "    deterministic=True,    # Ensure reproducibility\n",
    "    enable_progress_bar=True,  # Show progress bar\n",
    "    log_every_n_steps=10       # Log metrics every 10 steps\n",
    ")\n",
    "\n",
    "# Data loaders with persistent workers for faster training\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True  # Pin memory for faster data transfer to GPU\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "best_model = LitBrainTumor.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path,  # Path to the best checkpoint\n",
    "    class_weights=class_weights  # Pass class weights to the loaded model\n",
    ")\n",
    "\n",
    "# Test the best model\n",
    "trainer.test(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: c:\\Users\\DELL 5540\\Desktop\\Brain Tumour\\lightning_logs\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | BrainTumorDeiT         | 86.2 M\n",
      "1 | criterion | SoftTargetCrossEntropy | 0     \n",
      "2 | train_acc | MulticlassAccuracy     | 0     \n",
      "3 | val_acc   | MulticlassAccuracy     | 0     \n",
      "4 | test_acc  | MulticlassAccuracy     | 0     \n",
      "5 | f1        | MulticlassF1Score      | 0     \n",
      "-----------------------------------------------------\n",
      "28.7 M    Trainable params\n",
      "57.4 M    Non-trainable params\n",
      "86.2 M    Total params\n",
      "344.782   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f8d3cf56ba44c7a67dd81ca08f3ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c31864379014692b0f2614cf65fcd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1000) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%% Training Execution Cell\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m best_model \u001b[38;5;241m=\u001b[39m LitBrainTumor\u001b[38;5;241m.\u001b[39mload_from_checkpoint(\n\u001b[0;32m      4\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path,\n\u001b[0;32m      5\u001b[0m     class_weights\u001b[38;5;241m=\u001b[39mclass_weights\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 545\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    575\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    577\u001b[0m     ckpt_path,\n\u001b[0;32m    578\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    580\u001b[0m )\n\u001b[1;32m--> 581\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 990\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1036\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1034\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1036\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m         closure()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\core\\module.py:1282\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1245\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1249\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \n\u001b[0;32m   1281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1282\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\core\\optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:74\u001b[0m, in \u001b[0;36mMixedPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     67\u001b[0m     optimizer: Optimizable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;66;03m# skip scaler logic, as bfloat16 does not require scaler\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(optimizer, LBFGS):\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py:117\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:161\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 161\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    164\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision_plugin.py:104\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 126\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 57\u001b[0m, in \u001b[0;36mLitBrainTumor.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     55\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixup_fn(x, y)\n\u001b[0;32m     56\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[1;32m---> 57\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_acc(logits\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, prog_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\timm\\loss\\cross_entropy.py:35\u001b[0m, in \u001b[0;36mSoftTargetCrossEntropy.forward\u001b[1;34m(self, x, target)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, target: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 35\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1000) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#%% Training Execution Cell\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "best_model = LitBrainTumor.load_from_checkpoint(\n",
    "    trainer.checkpoint_callback.best_model_path,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Evaluation Cell\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=train_dataset.classes,\n",
    "                yticklabels=train_dataset.classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_targets, all_preds, target_names=train_dataset.classes))\n",
    "\n",
    "evaluate_model(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Visualization Cell\n",
    "def plot_training_curves(trainer):\n",
    "    metrics = trainer.logged_metrics\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(metrics['train_loss_epoch'], label='Train')\n",
    "    plt.plot(metrics['val_loss_epoch'], label='Validation')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(metrics['train_acc_epoch'], label='Train')\n",
    "    plt.plot(metrics['val_acc_epoch'], label='Validation')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_curves(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Inference Cell\n",
    "def predict(image_path, model=best_model):\n",
    "    # Preprocessing pipeline\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE + 32),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = preprocess(img).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "    \n",
    "    return {cls: f\"{prob:.2%}\" for cls, prob in zip(train_dataset.classes, probs[0].tolist())}\n",
    "\n",
    "# Example usage\n",
    "sample_image = \"/path/to/test_image.jpg\"\n",
    "print(predict(sample_image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
